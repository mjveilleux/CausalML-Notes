\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}

\title{Information Theory}
\author{Mason Veilleux}
\date{October 2022}

\begin{document}

\maketitle

\section{Introduction}

This paper is intended to be notes the online lecture series "Information Theory, Pattern Recognition, and Neural Networks"


\section{Lecture 1: introduction to Information Theory}

The binomial distribution will appaer throughout the course. Get used to it.

Mean of binaomial distribution:
\begin{equation}
    \mu = Np
\end{equation}
 where $N$ is the number of observations and $p$ is the probability of event occuring. The variance of binomial distribution is:

 \begin{equation}
    Npq = \sigma^2 = \sqrt{\sigma^2} = \sigma
 \end{equation}


This comes from a common information channel: Binary symmetric channel



\end{document}

